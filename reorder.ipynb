{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "df = pl.read_csv('./connectome_graph.csv')\n",
    "\n",
    "# Extract arrays\n",
    "source_nodes = df[df.columns[0]].to_numpy().astype(np.int64)\n",
    "target_nodes = df[df.columns[1]].to_numpy().astype(np.int64)\n",
    "edge_weights = df[df.columns[2]].to_numpy().astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique node IDs and map to indices\n",
    "unique_nodes = np.unique(np.concatenate((source_nodes, target_nodes)))\n",
    "node_id_to_index = {node_id: idx for idx, node_id in enumerate(unique_nodes)}\n",
    "index_to_node_id = {idx: node_id for node_id, idx in node_id_to_index.items()}\n",
    "\n",
    "# Map node IDs to indices in edge lists\n",
    "source_indices = np.array([node_id_to_index[node_id] for node_id in source_nodes])\n",
    "target_indices = np.array([node_id_to_index[node_id] for node_id in target_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 10:47:37.016780: W external/xla/xla/service/gpu/nvptx_compiler.cc:893] The NVIDIA driver's CUDA version is 12.5 which is older than the PTX compiler version 12.6.68. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax import random\n",
    "\n",
    "# Convert to JAX arrays\n",
    "source_indices = jnp.array(source_indices)\n",
    "target_indices = jnp.array(target_indices)\n",
    "edge_weights = jnp.array(edge_weights)\n",
    "\n",
    "# Compute maximum edge weight\n",
    "total_edge_weight = jnp.max(edge_weights)\n",
    "\n",
    "# Normalize edge weights\n",
    "edge_weights = edge_weights / total_edge_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "def calculate_node_forward(source_orders, target_orders, edge_weights):\n",
    "    forward_edges = source_orders < target_orders\n",
    "\n",
    "    # Calculate total forward edge weight\n",
    "    forward_edge_weight = jnp.sum(edge_weights * forward_edges)\n",
    "    print(forward_edge_weight)\n",
    "    # Calculate total edge weight (for normalization)\n",
    "    total_edge_weight = jnp.sum(edge_weights)\n",
    "\n",
    "    # Calculate percentage of forward edge weight\n",
    "    percentage_forward = 100 * (forward_edge_weight / total_edge_weight)\n",
    "    return percentage_forward\n",
    "    # print(f\"Baseline Percentage of forward edge weight baseline: {percentage_forward:.2f}%\")\n",
    "import pandas as pd\n",
    "baseline_ordering = pd.read_csv('./ordered_nodes_84.54927062988281_brute.csv')\n",
    "\n",
    "node_ids = baseline_ordering['Node ID'].to_numpy()\n",
    "orders = jnp.arange(len(node_ids))\n",
    "\n",
    "# Create a sorting index\n",
    "sort_idx = np.argsort(node_ids)\n",
    "\n",
    "# Sort both arrays using this index\n",
    "sorted_node_ids = node_ids[sort_idx]\n",
    "sorted_orders = orders[sort_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_order = jnp.zeros(orders.shape[0])\n",
    "node_order = node_order.at[sort_idx].set(jnp.arange(orders.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Forward Edge Weight (Initial): 14734.474609375\n",
      "Percentage of Forward Edge Weight (Initial): 84.55%\n"
     ]
    }
   ],
   "source": [
    "num_nodes = len(unique_nodes)\n",
    "key = random.PRNGKey(0)\n",
    "# base_positions = np.load('./positions_84.09818529671391_999.npy')\n",
    "base_positions = (sort_idx / jnp.max(sort_idx))\n",
    "# base_positions = random.uniform(key, shape=(num_nodes,))\n",
    "positions = base_positions\n",
    "sorted_indices = jnp.argsort(positions)\n",
    "\n",
    "# Create a mapping from node index to order in the sequence\n",
    "node_order = jnp.zeros(num_nodes, dtype=int)\n",
    "node_order = node_order.at[sorted_indices].set(jnp.arange(num_nodes))\n",
    "\n",
    "edge_directions = node_order[target_indices] - node_order[source_indices]\n",
    "\n",
    "forward_edges = edge_directions > 0\n",
    "\n",
    "total_forward_weight_initial = jnp.sum(edge_weights * forward_edges)\n",
    "\n",
    "total_edge_weight = jnp.sum(edge_weights)\n",
    "original_total_edge_weights = total_edge_weight\n",
    "# Compute the percentage of forward edge weight\n",
    "percentage_forward_initial = 100 * float(total_forward_weight_initial) / (total_edge_weight)\n",
    "\n",
    "# Convert to JAX arrays\n",
    "source_indices = jnp.array(source_indices)\n",
    "target_indices = jnp.array(target_indices)\n",
    "edge_weights = jnp.array(edge_weights)\n",
    "\n",
    "# Compute maximum edge weight\n",
    "mean_edge_weight = jnp.max(edge_weights)\n",
    "\n",
    "# Normalize edge weights\n",
    "edge_weights = edge_weights / mean_edge_weight\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total Forward Edge Weight (Initial): {total_forward_weight_initial}\")\n",
    "print(f\"Percentage of Forward Edge Weight (Initial): {percentage_forward_initial:.2f}%\")\n",
    "best_metric=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def monte_carlo_node_ordering(source_indices, target_indices, node_order, edge_weights, num_iterations=200000000, temp=1.0):\n",
    "    num_nodes = node_order.shape[0]\n",
    "    num_edges = source_indices.shape[0]\n",
    "\n",
    "    source_indices = jnp.array(source_indices)\n",
    "    target_indices = jnp.array(target_indices)\n",
    "    node_order = node_order.astype(float)\n",
    "\n",
    "    # Function to compute the forward score\n",
    "    def calculate_forward_score(node_order):\n",
    "        source_order = node_order[source_indices]\n",
    "        target_order = node_order[target_indices]\n",
    "        forward_edges = source_order < target_order\n",
    "        return jnp.sum(edge_weights * forward_edges)\n",
    "\n",
    "    # Initial score\n",
    "    current_score = calculate_forward_score(node_order)\n",
    "\n",
    "    # Initial PRNGKey\n",
    "    key = jax.random.PRNGKey(0)\n",
    "\n",
    "    def monte_carlo_step(state):\n",
    "        node_order, current_score, iteration, temp, key = state\n",
    "\n",
    "        # Split the key for reproducibility\n",
    "        key, subkey_i, subkey_j, subkey_accept = jax.random.split(key, 4)\n",
    "\n",
    "        # Sample two random nodes to swap\n",
    "        i = jax.random.randint(subkey_i, (), 0, num_nodes)\n",
    "        j = jax.random.randint(subkey_j, (), 0, num_nodes)\n",
    "\n",
    "        # Ensure that i != j using jax.lax.while_loop\n",
    "        def cond_fun(val):\n",
    "            _, j = val\n",
    "            return j == i\n",
    "\n",
    "        def body_fun(val):\n",
    "            key_j, _ = val\n",
    "            key_j, subkey_new_j = jax.random.split(key_j)\n",
    "            new_j = jax.random.randint(subkey_new_j, (), 0, num_nodes)\n",
    "            return key_j, new_j\n",
    "\n",
    "        key_j, j = jax.lax.while_loop(cond_fun, body_fun, (key, j))\n",
    "\n",
    "        # Update key with the latest key_j\n",
    "        key = key_j\n",
    "\n",
    "        # Swap positions of node i and node j\n",
    "        new_node_order = node_order.at[i].set(node_order[j])\n",
    "        new_node_order = new_node_order.at[j].set(node_order[i])\n",
    "\n",
    "        # Compute new score\n",
    "        new_score = calculate_forward_score(new_node_order)\n",
    "\n",
    "        # Acceptance probability (simulated annealing)\n",
    "        delta = new_score - current_score\n",
    "        accept_prob = jnp.exp(delta / temp)  # Probabilistically accept worse solutions based on temperature\n",
    "\n",
    "        random_value = jax.random.uniform(subkey_accept, ())\n",
    "\n",
    "        # Update state based on acceptance criterion\n",
    "        accept_swap = (delta > 0) #| (random_value < accept_prob)\n",
    "\n",
    "        node_order = jax.lax.select(accept_swap, new_node_order, node_order)\n",
    "        current_score = jax.lax.select(accept_swap, new_score, current_score)\n",
    "\n",
    "        return node_order, current_score, iteration + 1, temp, key\n",
    "\n",
    "    # Initial state for the Monte Carlo loop\n",
    "    state = (node_order, current_score, 0, temp, key)\n",
    "\n",
    "    # Loop for a given number of iterations\n",
    "    def cond_fun(state):\n",
    "        node_order, _, iteration, _, _ = state\n",
    "        def check_metric_fn(_):\n",
    "            source_order = node_order[source_indices]\n",
    "            target_order = node_order[target_indices]\n",
    "            metric = calculate_node_forward(source_order, target_order, edge_weights)\n",
    "            jax.debug.print(\"Iteration {iteration}, metric {metric}, score {current_score}\", iteration=iteration, metric=metric, current_score=current_score)\n",
    "            return None\n",
    "\n",
    "        # Conditionally run the metric check\n",
    "        jax.lax.cond(iteration % 100000 == 0, check_metric_fn, lambda _: None, operand=None)\n",
    "\n",
    "        return iteration < num_iterations\n",
    "\n",
    "    state = jax.lax.while_loop(cond_fun, monte_carlo_step, state)\n",
    "    final_node_order, final_score, _, _, _ = state\n",
    "\n",
    "    return final_node_order, final_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=2/0)>\n",
      "Iteration 0, metric 84.54927062988281, score 14734.474609375\n",
      "Iteration 100000, metric 84.54927062988281, score 14734.474609375\n",
      "Iteration 200000, metric 84.54927062988281, score 14734.474609375\n",
      "Iteration 300000, metric 84.54927062988281, score 14734.474609375\n",
      "Iteration 400000, metric 84.54927062988281, score 14734.474609375\n",
      "Iteration 500000, metric 84.54927062988281, score 14734.474609375\n",
      "Iteration 600000, metric 84.54927062988281, score 14734.474609375\n",
      "Iteration 700000, metric 84.54927062988281, score 14734.474609375\n",
      "Iteration 800000, metric 84.54927062988281, score 14734.474609375\n",
      "Iteration 900000, metric 84.54927062988281, score 14734.474609375\n",
      "Iteration 1000000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 1100000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 1200000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 1300000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 1400000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 1500000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 1600000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 1700000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 1800000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 1900000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 2000000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 2100000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 2200000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 2300000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 2400000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 2500000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 2600000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 2700000, metric 84.54928588867188, score 14734.474609375\n",
      "Iteration 2800000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 2900000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 3000000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 3100000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 3200000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 3300000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 3400000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 3500000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 3600000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 3700000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 3800000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 3900000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 4000000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 4100000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 4200000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 4300000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 4400000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 4500000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 4600000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 4700000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 4800000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 4900000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 5000000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 5100000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 5200000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 5300000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 5400000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 5500000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 5600000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 5700000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 5800000, metric 84.5492935180664, score 14734.474609375\n",
      "Iteration 5900000, metric 84.5492935180664, score 14734.474609375\n"
     ]
    }
   ],
   "source": [
    "print(\"START\")\n",
    "node_order, best_metric = monte_carlo_node_ordering(source_indices, target_indices, node_order, edge_weights, temp=1e-3)\n",
    "\n",
    "source_order = node_order[source_indices]\n",
    "target_order = node_order[target_indices]\n",
    "metric = calculate_node_forward(source_order, target_order, edge_weights)\n",
    "ordered_node_ids = [index_to_node_id[int(idx)] for idx in node_order]\n",
    "\n",
    "ordered_nodes_df = pd.DataFrame({\"Node ID\": ordered_node_ids, \"Order\": jnp.arange(node_order.shape[0])})\n",
    "ordered_nodes_df.to_csv(f\"./ordered_nodes_{metric}_brute.csv\", index=False)\n",
    "print(\"FINISHED\", metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14734.475\n",
      "84.54927\n"
     ]
    }
   ],
   "source": [
    "node_order_8514 = jnp.array(node_order)\n",
    "source_order = node_order_8514[source_indices]\n",
    "target_order = node_order_8514[target_indices]\n",
    "metric = calculate_node_forward(source_order, target_order, edge_weights)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_indices = jnp.argsort(positions)\n",
    "node_order = jnp.zeros(num_nodes)\n",
    "node_order = node_order.at[node_order_8514.astype(int)].set(jnp.arange(num_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ordering to a CSV file\n",
    "import pandas as pd\n",
    "ordered_node_ids = [index_to_node_id[int(idx)] for idx in node_order]\n",
    "\n",
    "ordered_nodes_df = pd.DataFrame({\"Node ID\": ordered_node_ids, \"Order\": jnp.arange(node_order.shape[0])})\n",
    "ordered_nodes_df.to_csv(f\"./ordered_nodes_{metric}_brute.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
